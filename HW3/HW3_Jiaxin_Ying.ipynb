{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helenyjx/AIPI531-Deep-Reinforcement-Learning-Applications/blob/main/HW3/HW3_Jiaxin_Ying.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcbtZaGoV8SD"
      },
      "source": [
        "# AIPI 531 HW3 Jiaxin Ying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Viofs35ZsXV7"
      },
      "source": [
        "## Installing DRL2\n",
        "\n",
        "Base codes for the paper https://arxiv.org/pdf/2111.03474.pdf can found here : https://drive.google.com/file/d/185KB520pBLgwmiuEe7JO78kUwUL_F45t/view?usp=sharing\n",
        "\n",
        "- copy the contents of the zipped folder to your drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q57UamuUsTW7",
        "outputId": "0f3a7f04-cc4b-4b4b-ef9f-f64b588d0720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/HW3/SA2C_code/Kaggle\n",
            "data\t\t     preprocess_kaggle.py  report_SNQN.txt   SNQN_new.py\t split_data.py\n",
            "DQN_NS.py\t     __pycache__\t   SA2C_new.py\t     SNQN_parent_new.py  test.py\n",
            "NextItNetModules.py  replay_buffer.py\t   SA2C.py\t     SNQN_parent.py\t utility.py\n",
            "pop.py\t\t     report_SA2C.txt\t   SASRecModules.py  SNQN.py\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PROJ_DIR = '/content/drive/MyDrive/HW3/SA2C_code/Kaggle'   ## give your drive folder location\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkvS3yyrxw_0"
      },
      "source": [
        "### Need to upgrade the code to tf2\n",
        "\n",
        "- will create a new script with the upgraded code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO3az4Rpxc6D",
        "outputId": "ed2adca4-76fd-497a-c40c-b8800ddcba72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-17 18:28:03.301843: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-17 18:28:03.301897: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-17 18:28:03.301959: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-17 18:28:03.309200: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-17 18:28:04.399754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO line 65:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 68:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 70:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 71:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "WARNING line 75:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "INFO line 78:46: Renamed 'tf.nn.dynamic_rnn' to 'tf.compat.v1.nn.dynamic_rnn'\n",
            "INFO line 79:20: Renamed 'tf.contrib.rnn.GRUCell' to 'tf.compat.v1.nn.rnn_cell.GRUCell'\n",
            "INFO line 86:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "INFO line 96:25: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 96:25: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 99:40: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n",
            "INFO line 102:31: Added keywords to args of function 'tf.nn.conv2d'\n",
            "INFO line 102:31: Renamed keyword argument for tf.nn.conv2d from filter to filters\n",
            "INFO line 113:33: Added keywords to args of function 'tf.nn.max_pool'\n",
            "INFO line 113:33: Renamed keyword argument for tf.nn.max_pool from value to input\n",
            "INFO line 113:33: Renamed 'tf.nn.max_pool' to 'tf.nn.max_pool2d'\n",
            "INFO line 126:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 126:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 128:36: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n",
            "INFO line 130:27: Added keywords to args of function 'tf.nn.conv2d'\n",
            "INFO line 130:27: Renamed keyword argument for tf.nn.conv2d from filter to filters\n",
            "INFO line 141:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 141:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 142:41: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n",
            "INFO line 147:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "WARNING line 156:36: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "WARNING line 171:26: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "INFO line 176:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "INFO line 178:27: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n",
            "INFO line 186:25: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 212:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 214:34: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 216:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 217:37: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 219:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 220:28: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 222:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 223:44: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 242:23: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 247:17: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 248:47: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 250:45: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 335:4: Renamed 'tf.reset_default_graph' to 'tf.compat.v1.reset_default_graph'\n",
            "INFO line 346:9: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n",
            "INFO line 348:17: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 1 files\n",
            "Detected 3 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "File: SNQN.py\n",
            "--------------------------------------------------------------------------------\n",
            "SNQN.py:75:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "SNQN.py:156:36: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "SNQN.py:171:26: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report_SA2C.txt'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!tf_upgrade_v2 \\\n",
        "  --infile 'SNQN.py' \\\n",
        "  --outfile 'SNQN_new.py' \\\n",
        "  --reportfile report_SA2C.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJvfJSpE_hH0",
        "outputId": "db262e54-7781-47b5-cf73-750f58bc2fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-17 18:29:43.659200: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-17 18:29:43.659263: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-17 18:29:43.659304: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-17 18:29:43.666839: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-17 18:29:44.762452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO line 1:0: Not upgrading symbols because `tensorflow.compat.v1` was directly imported as `tf`.\n",
            "INFO line 3:0: Renamed 'tf.disable_v2_behavior' to 'tf.compat.v1.disable_v2_behavior'\n",
            "INFO line 102:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 105:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 107:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 110:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "WARNING line 115:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "INFO line 150:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 152:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 154:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 155:37: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 158:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 159:28: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 161:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 162:44: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 198:23: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 203:17: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 205:20: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 209:20: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 318:4: Renamed 'tf.reset_default_graph' to 'tf.compat.v1.reset_default_graph'\n",
            "INFO line 343:9: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n",
            "INFO line 345:17: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 1 files\n",
            "Detected 1 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "File: SNQN_parent.py\n",
            "--------------------------------------------------------------------------------\n",
            "SNQN_parent.py:115:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report_SNQN.txt'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!tf_upgrade_v2 \\\n",
        "  --infile 'SNQN_parent.py' \\\n",
        "  --outfile 'SNQN_parent_new.py' \\\n",
        "  --reportfile report_SNQN.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2l7P7Wsygbh"
      },
      "source": [
        "## Install trfl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGrknIS0x6pu",
        "outputId": "cc4ab957-605f-4f02-9095-12e708ceb5bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pandas trfl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_QzXbZTzB-c"
      },
      "source": [
        "## Possible errors while running the DRL2 script\n",
        "\n",
        "Make the below changes to the original SA2C or SNQN code\n",
        "1. RuntimeError: tf.placeholder() is not compatible with eager execution.\n",
        "Solution: disable eager execution - You can place this on the first line of the init funtion: `tf.compat.v1.disable_eager_execution()`\n",
        "2. AttributeError: module 'tensorflow' has no attribute 'contrib'\n",
        "Solution: Replace the fully_connected() layers with dense() layers in every file you work with\n",
        "Replace\n",
        "\n",
        "```\n",
        " self.output1 = tf.contrib.layers.fully_connected(self.states_hidden, self.item_num,activation_fn=None)  # all q-values\n",
        "```\n",
        "\n",
        "\n",
        "  with\n",
        "\n",
        "```\n",
        "self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
        "activation=None)  # all q-values\n",
        "```\n",
        "\n",
        "After you make the changes, reupload the file to the drive and execute the `tf_upgrade_v2` command with the newly modified file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3VjPqLaynux"
      },
      "source": [
        "# Performance comparison between the recommenders with and without item features.\n",
        "## Run the DRL2 recommender script: Training Different Session-based Recommenders\n",
        "Trained two types of session-based recommenders using Deep Reinforcement Learning (DRL), specifically a GRU-based model. The first model (SNQN.py) is trained without item features, and the second model (SNQN_parent.py) includes item features. This distinction is crucial for evaluating the impact of item features on recommendation performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93h_rP04ENna"
      },
      "source": [
        "- specify the base recommender - GRU without item features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CRx5iXlyjGm",
        "outputId": "0e1670e0-3f8a-4c3e-99fe-197e2e63b8ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-16 23:09:58.873405: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-16 23:09:58.873455: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-16 23:09:58.873495: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-16 23:09:58.881080: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-16 23:10:00.318845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/drive/MyDrive/HW3/SA2C_code/Kaggle/SNQN_new.py:79: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/HW3/SA2C_code/Kaggle/SNQN_new.py:78: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "2023-11-16 23:10:06.331481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:06.948649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:06.948996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:06.950565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:06.954193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:06.954421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:10.260985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:10.261329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:10.261516: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-16 23:10:10.261611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:10.261792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "/content/drive/MyDrive/HW3/SA2C_code/Kaggle/SNQN_new.py:207: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, activation=None)  # all q-values\n",
            "/content/drive/MyDrive/HW3/SA2C_code/Kaggle/SNQN_new.py:208: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num, use_bias=True, activation=None)\n",
            "2023-11-16 23:10:17.209068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:17.209369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:17.209528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:17.209734: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:17.209922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-16 23:10:17.210057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-11-16 23:10:17.233814: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 2.600000\n",
            "clicks hr ndcg @ 5 : 0.000068, 0.000031\n",
            "purchase hr and ndcg @5 : 0.000189, 0.000189\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 5.200000\n",
            "clicks hr ndcg @ 10 : 0.000178, 0.000066\n",
            "purchase hr and ndcg @10 : 0.000189, 0.000189\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8.200000\n",
            "clicks hr ndcg @ 15 : 0.000262, 0.000088\n",
            "purchase hr and ndcg @15 : 0.000378, 0.000239\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10.800000\n",
            "clicks hr ndcg @ 20 : 0.000372, 0.000114\n",
            "purchase hr and ndcg @20 : 0.000378, 0.000239\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.925306\n",
            "the loss in 400th batch is: 10.726124\n",
            "the loss in 600th batch is: 10.518625\n",
            "the loss in 800th batch is: 10.167098\n",
            "the loss in 1000th batch is: 10.481197\n",
            "the loss in 1200th batch is: 10.228475\n",
            "the loss in 1400th batch is: 9.865973\n",
            "the loss in 1600th batch is: 10.027100\n",
            "the loss in 1800th batch is: 9.869293\n",
            "the loss in 2000th batch is: 9.677183\n",
            "the loss in 2200th batch is: 9.669882\n",
            "the loss in 2400th batch is: 9.839115\n",
            "the loss in 2600th batch is: 9.119152\n",
            "the loss in 2800th batch is: 9.376966\n",
            "the loss in 3000th batch is: 9.002368\n",
            "the loss in 3200th batch is: 8.962450\n",
            "the loss in 3400th batch is: 9.110555\n",
            "the loss in 3600th batch is: 8.561526\n",
            "the loss in 3800th batch is: 8.590637\n",
            "the loss in 4000th batch is: 8.690551\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5869.200000\n",
            "clicks hr ndcg @ 5 : 0.168047, 0.132758\n",
            "purchase hr and ndcg @5 : 0.357777, 0.306388\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6803.200000\n",
            "clicks hr ndcg @ 10 : 0.198096, 0.142499\n",
            "purchase hr and ndcg @10 : 0.399924, 0.320172\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7315.200000\n",
            "clicks hr ndcg @ 15 : 0.215678, 0.147155\n",
            "purchase hr and ndcg @15 : 0.418068, 0.324967\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7665.400000\n",
            "clicks hr ndcg @ 20 : 0.227605, 0.149974\n",
            "purchase hr and ndcg @20 : 0.430920, 0.327996\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.456757\n",
            "the loss in 4400th batch is: 8.063802\n",
            "the loss in 4600th batch is: 8.432204\n",
            "the loss in 4800th batch is: 7.896797\n",
            "the loss in 5000th batch is: 8.626282\n",
            "the loss in 5200th batch is: 7.942946\n",
            "the loss in 5400th batch is: 8.319081\n",
            "the loss in 5600th batch is: 7.876572\n",
            "the loss in 5800th batch is: 7.675574\n",
            "the loss in 6000th batch is: 7.770785\n",
            "the loss in 6200th batch is: 7.829017\n",
            "the loss in 6400th batch is: 7.263196\n",
            "the loss in 6600th batch is: 7.908008\n",
            "the loss in 6800th batch is: 7.595408\n",
            "the loss in 7000th batch is: 7.745680\n",
            "the loss in 7200th batch is: 7.691066\n",
            "the loss in 7400th batch is: 7.309265\n",
            "the loss in 7600th batch is: 7.006498\n",
            "the loss in 7800th batch is: 7.177048\n",
            "the loss in 8000th batch is: 7.435240\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8082.800000\n",
            "clicks hr ndcg @ 5 : 0.233369, 0.184150\n",
            "purchase hr and ndcg @5 : 0.484029, 0.416296\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 9299.400000\n",
            "clicks hr ndcg @ 10 : 0.275024, 0.197641\n",
            "purchase hr and ndcg @10 : 0.527689, 0.430523\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9945.400000\n",
            "clicks hr ndcg @ 15 : 0.297846, 0.203677\n",
            "purchase hr and ndcg @15 : 0.547723, 0.435861\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10403.000000\n",
            "clicks hr ndcg @ 20 : 0.313889, 0.207465\n",
            "purchase hr and ndcg @20 : 0.562465, 0.439354\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 6.912055\n",
            "the loss in 8400th batch is: 6.715075\n",
            "the loss in 8600th batch is: 6.893593\n",
            "the loss in 8800th batch is: 6.967363\n",
            "the loss in 9000th batch is: 6.698061\n",
            "the loss in 9200th batch is: 7.197092\n",
            "the loss in 9400th batch is: 6.634221\n",
            "the loss in 9600th batch is: 6.889596\n",
            "the loss in 9800th batch is: 6.739642\n",
            "the loss in 10000th batch is: 6.870667\n",
            "the loss in 10200th batch is: 6.932117\n",
            "the loss in 10400th batch is: 7.335663\n",
            "the loss in 10600th batch is: 6.396971\n",
            "the loss in 10800th batch is: 6.661247\n",
            "the loss in 11000th batch is: 6.233564\n",
            "the loss in 11200th batch is: 6.357713\n",
            "the loss in 11400th batch is: 6.374145\n",
            "the loss in 11600th batch is: 6.745498\n",
            "the loss in 11800th batch is: 6.646608\n",
            "the loss in 12000th batch is: 6.640443\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8721.800000\n",
            "clicks hr ndcg @ 5 : 0.253318, 0.198049\n",
            "purchase hr and ndcg @5 : 0.515593, 0.438164\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 10120.400000\n",
            "clicks hr ndcg @ 10 : 0.301016, 0.213523\n",
            "purchase hr and ndcg @10 : 0.566623, 0.454751\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 10844.600000\n",
            "clicks hr ndcg @ 15 : 0.327016, 0.220395\n",
            "purchase hr and ndcg @15 : 0.587224, 0.460179\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11343.000000\n",
            "clicks hr ndcg @ 20 : 0.345502, 0.224764\n",
            "purchase hr and ndcg @20 : 0.598753, 0.462900\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.436400\n",
            "the loss in 12400th batch is: 6.432889\n",
            "the loss in 12600th batch is: 6.155165\n",
            "the loss in 12800th batch is: 5.946116\n",
            "the loss in 13000th batch is: 6.329676\n",
            "the loss in 13200th batch is: 6.048956\n",
            "the loss in 13400th batch is: 6.272102\n",
            "the loss in 13600th batch is: 7.058225\n",
            "the loss in 13800th batch is: 6.606142\n",
            "the loss in 14000th batch is: 6.184767\n",
            "the loss in 14200th batch is: 5.997858\n",
            "the loss in 14400th batch is: 5.997952\n",
            "the loss in 14600th batch is: 6.087495\n",
            "the loss in 14800th batch is: 5.945890\n",
            "the loss in 15000th batch is: 6.119814\n",
            "the loss in 15200th batch is: 5.839525\n",
            "the loss in 15400th batch is: 5.756692\n",
            "the loss in 15600th batch is: 6.359332\n",
            "the loss in 15800th batch is: 6.130144\n",
            "the loss in 16000th batch is: 5.957588\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8995.600000\n",
            "clicks hr ndcg @ 5 : 0.261382, 0.203835\n",
            "purchase hr and ndcg @5 : 0.531280, 0.445654\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 10409.800000\n",
            "clicks hr ndcg @ 10 : 0.310458, 0.219718\n",
            "purchase hr and ndcg @10 : 0.579097, 0.461206\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 11170.600000\n",
            "clicks hr ndcg @ 15 : 0.337794, 0.226964\n",
            "purchase hr and ndcg @15 : 0.600643, 0.466924\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11687.200000\n",
            "clicks hr ndcg @ 20 : 0.356457, 0.231373\n",
            "purchase hr and ndcg @20 : 0.614818, 0.470290\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 6.104158\n",
            "the loss in 16400th batch is: 6.161617\n",
            "the loss in 16600th batch is: 6.197216\n",
            "the loss in 16800th batch is: 6.000209\n",
            "the loss in 17000th batch is: 5.695770\n",
            "the loss in 17200th batch is: 5.805773\n",
            "the loss in 17400th batch is: 6.380673\n",
            "the loss in 17600th batch is: 6.334905\n",
            "the loss in 17800th batch is: 5.727711\n",
            "the loss in 18000th batch is: 5.638209\n",
            "the loss in 18200th batch is: 5.775470\n",
            "the loss in 18400th batch is: 6.192812\n",
            "the loss in 18600th batch is: 5.719205\n",
            "the loss in 18800th batch is: 6.023054\n",
            "the loss in 19000th batch is: 6.267450\n",
            "the loss in 19200th batch is: 5.886949\n"
          ]
        }
      ],
      "source": [
        "! python SNQN_new.py --model=GRU --epoch=5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K9JY_N0EPVu"
      },
      "source": [
        "- specify the base recommender - GRU with item features\n",
        "\n",
        "The inclusion of item features in SNQN_parent.py aligns with the DRL-based recommender systems discussed in the cited paper (https://arxiv.org/abs/2111.03474).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L77kHCB-cweN",
        "outputId": "95dfaa0b-f624-4b4a-ee8b-3838cbf68f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-17 18:34:48.922966: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-17 18:34:48.923020: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-17 18:34:48.923054: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-17 18:34:48.930447: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-17 18:34:50.024090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "/content/drive/MyDrive/HW3/SA2C_code/Kaggle/SNQN_parent_new.py:121: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/HW3/SA2C_code/Kaggle/SNQN_parent_new.py:120: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/drive/MyDrive/HW3/SA2C_code/Kaggle/SNQN_parent_new.py:127: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(\n",
            "/content/drive/MyDrive/HW3/SA2C_code/Kaggle/SNQN_parent_new.py:130: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(\n",
            "/content/drive/MyDrive/HW3/SA2C_code/Kaggle/SNQN_parent_new.py:134: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.w_f = tf.compat.v1.layers.dense(\n",
            "2023-11-17 18:35:04.920151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 18:35:05.401730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 18:35:05.402047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 18:35:05.402832: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 18:35:05.403076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 18:35:05.403283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 18:35:07.563083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 18:35:07.563384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 18:35:07.563529: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-17 18:35:07.563609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-17 18:35:07.563755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-11-17 18:35:07.888707: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.200000\n",
            "clicks hr ndcg @ 5 : 0.000008, 0.000004\n",
            "purchase hr and ndcg @5 : 0.000189, 0.000081\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.000000\n",
            "clicks hr ndcg @ 10 : 0.000042, 0.000014\n",
            "purchase hr and ndcg @10 : 0.000189, 0.000081\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 5.200000\n",
            "clicks hr ndcg @ 15 : 0.000135, 0.000039\n",
            "purchase hr and ndcg @15 : 0.000378, 0.000132\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7.800000\n",
            "clicks hr ndcg @ 20 : 0.000245, 0.000065\n",
            "purchase hr and ndcg @20 : 0.000378, 0.000132\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.895311\n",
            "the loss in 400th batch is: 10.825609\n",
            "the loss in 600th batch is: 10.483304\n",
            "the loss in 800th batch is: 10.667176\n",
            "the loss in 1000th batch is: 10.075061\n",
            "the loss in 1200th batch is: 10.209851\n",
            "the loss in 1400th batch is: 10.191470\n",
            "the loss in 1600th batch is: 9.894505\n",
            "the loss in 1800th batch is: 9.996483\n",
            "the loss in 2000th batch is: 9.898993\n",
            "the loss in 2200th batch is: 9.752111\n",
            "the loss in 2400th batch is: 9.551967\n",
            "the loss in 2600th batch is: 9.712730\n",
            "the loss in 2800th batch is: 9.197926\n",
            "the loss in 3000th batch is: 9.175151\n",
            "the loss in 3200th batch is: 9.275368\n",
            "the loss in 3400th batch is: 9.066460\n",
            "the loss in 3600th batch is: 8.512624\n",
            "the loss in 3800th batch is: 8.755400\n",
            "the loss in 4000th batch is: 8.949504\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5644.800000\n",
            "clicks hr ndcg @ 5 : 0.161310, 0.127317\n",
            "purchase hr and ndcg @5 : 0.345492, 0.295283\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6507.400000\n",
            "clicks hr ndcg @ 10 : 0.189441, 0.136428\n",
            "purchase hr and ndcg @10 : 0.382725, 0.307327\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7024.200000\n",
            "clicks hr ndcg @ 15 : 0.206845, 0.141037\n",
            "purchase hr and ndcg @15 : 0.402570, 0.312596\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7383.000000\n",
            "clicks hr ndcg @ 20 : 0.219177, 0.143955\n",
            "purchase hr and ndcg @20 : 0.415233, 0.315577\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.535584\n",
            "the loss in 4400th batch is: 8.335526\n",
            "the loss in 4600th batch is: 8.393558\n",
            "the loss in 4800th batch is: 8.466872\n",
            "the loss in 5000th batch is: 8.253036\n",
            "the loss in 5200th batch is: 8.455416\n",
            "the loss in 5400th batch is: 8.349436\n",
            "the loss in 5600th batch is: 7.973327\n",
            "the loss in 5800th batch is: 8.280713\n",
            "the loss in 6000th batch is: 7.604117\n",
            "the loss in 6200th batch is: 7.742470\n",
            "the loss in 6400th batch is: 7.894877\n",
            "the loss in 6600th batch is: 7.974859\n",
            "the loss in 6800th batch is: 7.540234\n",
            "the loss in 7000th batch is: 7.439335\n",
            "the loss in 7200th batch is: 7.370356\n",
            "the loss in 7400th batch is: 7.052864\n",
            "the loss in 7600th batch is: 7.964338\n",
            "the loss in 7800th batch is: 7.480509\n",
            "the loss in 8000th batch is: 7.533768\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 7915.800000\n",
            "clicks hr ndcg @ 5 : 0.228086, 0.180619\n",
            "purchase hr and ndcg @5 : 0.476091, 0.407446\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 9069.400000\n",
            "clicks hr ndcg @ 10 : 0.267248, 0.193327\n",
            "purchase hr and ndcg @10 : 0.518995, 0.421178\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9722.200000\n",
            "clicks hr ndcg @ 15 : 0.290061, 0.199365\n",
            "purchase hr and ndcg @15 : 0.540352, 0.426850\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10150.400000\n",
            "clicks hr ndcg @ 20 : 0.305369, 0.202984\n",
            "purchase hr and ndcg @20 : 0.552826, 0.429789\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 7.225844\n",
            "the loss in 8400th batch is: 7.460605\n",
            "the loss in 8600th batch is: 7.314413\n",
            "the loss in 8800th batch is: 7.037675\n",
            "the loss in 9000th batch is: 7.258806\n",
            "the loss in 9200th batch is: 6.982563\n",
            "the loss in 9400th batch is: 6.881788\n",
            "the loss in 9600th batch is: 6.762506\n",
            "the loss in 9800th batch is: 7.152145\n",
            "the loss in 10000th batch is: 6.424962\n",
            "the loss in 10200th batch is: 6.905341\n",
            "the loss in 10400th batch is: 6.697995\n",
            "the loss in 10600th batch is: 6.754255\n",
            "the loss in 10800th batch is: 6.858557\n",
            "the loss in 11000th batch is: 6.686277\n",
            "the loss in 11200th batch is: 7.006694\n",
            "the loss in 11400th batch is: 6.635503\n",
            "the loss in 11600th batch is: 6.726757\n",
            "the loss in 11800th batch is: 6.566514\n",
            "the loss in 12000th batch is: 6.594586\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8653.200000\n",
            "clicks hr ndcg @ 5 : 0.251348, 0.197921\n",
            "purchase hr and ndcg @5 : 0.511435, 0.438422\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 9971.000000\n",
            "clicks hr ndcg @ 10 : 0.296561, 0.212565\n",
            "purchase hr and ndcg @10 : 0.558307, 0.453639\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 10646.000000\n",
            "clicks hr ndcg @ 15 : 0.320525, 0.218907\n",
            "purchase hr and ndcg @15 : 0.578719, 0.459059\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11136.200000\n",
            "clicks hr ndcg @ 20 : 0.337861, 0.223002\n",
            "purchase hr and ndcg @20 : 0.593839, 0.462647\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.892647\n",
            "the loss in 12400th batch is: 6.426471\n",
            "the loss in 12600th batch is: 6.716124\n",
            "the loss in 12800th batch is: 6.541159\n",
            "the loss in 13000th batch is: 6.686099\n",
            "the loss in 13200th batch is: 6.463530\n",
            "the loss in 13400th batch is: 6.392015\n",
            "the loss in 13600th batch is: 6.036085\n",
            "the loss in 13800th batch is: 6.065751\n",
            "the loss in 14000th batch is: 6.272883\n",
            "the loss in 14200th batch is: 6.503095\n",
            "the loss in 14400th batch is: 6.500052\n",
            "the loss in 14600th batch is: 6.428775\n",
            "the loss in 14800th batch is: 6.089903\n",
            "the loss in 15000th batch is: 6.019432\n",
            "the loss in 15200th batch is: 6.156551\n",
            "the loss in 15400th batch is: 6.618266\n",
            "the loss in 15600th batch is: 6.167494\n",
            "the loss in 15800th batch is: 6.346951\n",
            "the loss in 16000th batch is: 5.986648\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8959.400000\n",
            "clicks hr ndcg @ 5 : 0.261669, 0.205047\n",
            "purchase hr and ndcg @5 : 0.523153, 0.443786\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 10354.000000\n",
            "clicks hr ndcg @ 10 : 0.310424, 0.220809\n",
            "purchase hr and ndcg @10 : 0.568702, 0.458645\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 11087.200000\n",
            "clicks hr ndcg @ 15 : 0.335875, 0.227555\n",
            "purchase hr and ndcg @15 : 0.593461, 0.465229\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11582.000000\n",
            "clicks hr ndcg @ 20 : 0.353617, 0.231744\n",
            "purchase hr and ndcg @20 : 0.607636, 0.468575\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 6.373177\n",
            "the loss in 16400th batch is: 6.035177\n",
            "the loss in 16600th batch is: 6.023970\n",
            "the loss in 16800th batch is: 5.820011\n",
            "the loss in 17000th batch is: 6.149910\n",
            "the loss in 17200th batch is: 5.886637\n",
            "the loss in 17400th batch is: 6.015053\n",
            "the loss in 17600th batch is: 5.921510\n",
            "the loss in 17800th batch is: 5.989096\n",
            "the loss in 18000th batch is: 5.811644\n",
            "the loss in 18200th batch is: 6.109134\n",
            "the loss in 18400th batch is: 5.797848\n",
            "the loss in 18600th batch is: 5.747447\n",
            "the loss in 18800th batch is: 5.976269\n",
            "the loss in 19000th batch is: 5.911942\n",
            "the loss in 19200th batch is: 6.106186\n"
          ]
        }
      ],
      "source": [
        "! python SNQN_parent_new.py --model=GRU --epoch=5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Defining the data\n",
        "data = {\n",
        "    \"Metric\": [\n",
        "        \"Cumulative Reward @ 5\", \"HR @ 5\", \"NDCG @ 5\",\n",
        "        \"Cumulative Reward @ 10\", \"HR @ 10\", \"NDCG @ 10\",\n",
        "        \"Cumulative Reward @ 15\", \"HR @ 15\", \"NDCG @ 15\",\n",
        "        \"Cumulative Reward @ 20\", \"HR @ 20\", \"NDCG @ 20\",\n",
        "        \"Loss in 16200th batch\", \"Loss in 16400th batch\", \"Loss in 16600th batch\",\n",
        "        \"Loss in 16800th batch\", \"Loss in 17000th batch\", \"Loss in 17200th batch\",\n",
        "        \"Loss in 17400th batch\", \"Loss in 17600th batch\", \"Loss in 17800th batch\",\n",
        "        \"Loss in 18000th batch\", \"Loss in 18200th batch\", \"Loss in 18400th batch\",\n",
        "        \"Loss in 18600th batch\", \"Loss in 18800th batch\", \"Loss in 19000th batch\",\n",
        "        \"Loss in 19200th batch\"\n",
        "    ],\n",
        "    \"❎ Item Features\": [\n",
        "        8995.6, 0.261382, 0.203835,\n",
        "        10409.8, 0.310458, 0.219718,\n",
        "        11170.6, 0.337794, 0.226964,\n",
        "        11687.2, 0.356457, 0.231373,\n",
        "        6.104158, 6.161617, 6.197216,\n",
        "        6.000209, 5.695770, 5.805773,\n",
        "        6.380673, 6.334905, 5.727711,\n",
        "        5.638209, 5.775470, 6.192812,\n",
        "        5.719205, 6.023054, 6.267450,\n",
        "        5.886949\n",
        "    ],\n",
        "    \"✅ Item Features\": [\n",
        "        8959.4, 0.261669, 0.205047,\n",
        "        10354.0, 0.310424, 0.220809,\n",
        "        11087.2, 0.335875, 0.227555,\n",
        "        11582.0, 0.353617, 0.231744,\n",
        "        6.373177, 6.035177, 6.023970,\n",
        "        5.820011, 6.149910, 5.886637,\n",
        "        6.015053, 5.921510, 5.989096,\n",
        "        5.811644, 6.109134, 5.797848,\n",
        "        5.747447, 5.976269, 5.911942,\n",
        "        6.106186\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df.set_index(\"Metric\", inplace=True)\n",
        "\n",
        "df.head(32) # Displaying the entire DataFrame\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "wjAHKt2UFbxf",
        "outputId": "f5567d08-e9a4-408a-e7bd-bbba2fb5f5d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        ❎ Item Features  ✅ Item Features\n",
              "Metric                                                  \n",
              "Cumulative Reward @ 5       8995.600000      8959.400000\n",
              "HR @ 5                         0.261382         0.261669\n",
              "NDCG @ 5                       0.203835         0.205047\n",
              "Cumulative Reward @ 10     10409.800000     10354.000000\n",
              "HR @ 10                        0.310458         0.310424\n",
              "NDCG @ 10                      0.219718         0.220809\n",
              "Cumulative Reward @ 15     11170.600000     11087.200000\n",
              "HR @ 15                        0.337794         0.335875\n",
              "NDCG @ 15                      0.226964         0.227555\n",
              "Cumulative Reward @ 20     11687.200000     11582.000000\n",
              "HR @ 20                        0.356457         0.353617\n",
              "NDCG @ 20                      0.231373         0.231744\n",
              "Loss in 16200th batch          6.104158         6.373177\n",
              "Loss in 16400th batch          6.161617         6.035177\n",
              "Loss in 16600th batch          6.197216         6.023970\n",
              "Loss in 16800th batch          6.000209         5.820011\n",
              "Loss in 17000th batch          5.695770         6.149910\n",
              "Loss in 17200th batch          5.805773         5.886637\n",
              "Loss in 17400th batch          6.380673         6.015053\n",
              "Loss in 17600th batch          6.334905         5.921510\n",
              "Loss in 17800th batch          5.727711         5.989096\n",
              "Loss in 18000th batch          5.638209         5.811644\n",
              "Loss in 18200th batch          5.775470         6.109134\n",
              "Loss in 18400th batch          6.192812         5.797848\n",
              "Loss in 18600th batch          5.719205         5.747447\n",
              "Loss in 18800th batch          6.023054         5.976269\n",
              "Loss in 19000th batch          6.267450         5.911942\n",
              "Loss in 19200th batch          5.886949         6.106186"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f2fb9d7-a5f6-4418-9f46-497b2fd10861\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>❎ Item Features</th>\n",
              "      <th>✅ Item Features</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Metric</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cumulative Reward @ 5</th>\n",
              "      <td>8995.600000</td>\n",
              "      <td>8959.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HR @ 5</th>\n",
              "      <td>0.261382</td>\n",
              "      <td>0.261669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NDCG @ 5</th>\n",
              "      <td>0.203835</td>\n",
              "      <td>0.205047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative Reward @ 10</th>\n",
              "      <td>10409.800000</td>\n",
              "      <td>10354.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HR @ 10</th>\n",
              "      <td>0.310458</td>\n",
              "      <td>0.310424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NDCG @ 10</th>\n",
              "      <td>0.219718</td>\n",
              "      <td>0.220809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative Reward @ 15</th>\n",
              "      <td>11170.600000</td>\n",
              "      <td>11087.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HR @ 15</th>\n",
              "      <td>0.337794</td>\n",
              "      <td>0.335875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NDCG @ 15</th>\n",
              "      <td>0.226964</td>\n",
              "      <td>0.227555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative Reward @ 20</th>\n",
              "      <td>11687.200000</td>\n",
              "      <td>11582.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HR @ 20</th>\n",
              "      <td>0.356457</td>\n",
              "      <td>0.353617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NDCG @ 20</th>\n",
              "      <td>0.231373</td>\n",
              "      <td>0.231744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 16200th batch</th>\n",
              "      <td>6.104158</td>\n",
              "      <td>6.373177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 16400th batch</th>\n",
              "      <td>6.161617</td>\n",
              "      <td>6.035177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 16600th batch</th>\n",
              "      <td>6.197216</td>\n",
              "      <td>6.023970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 16800th batch</th>\n",
              "      <td>6.000209</td>\n",
              "      <td>5.820011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 17000th batch</th>\n",
              "      <td>5.695770</td>\n",
              "      <td>6.149910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 17200th batch</th>\n",
              "      <td>5.805773</td>\n",
              "      <td>5.886637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 17400th batch</th>\n",
              "      <td>6.380673</td>\n",
              "      <td>6.015053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 17600th batch</th>\n",
              "      <td>6.334905</td>\n",
              "      <td>5.921510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 17800th batch</th>\n",
              "      <td>5.727711</td>\n",
              "      <td>5.989096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 18000th batch</th>\n",
              "      <td>5.638209</td>\n",
              "      <td>5.811644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 18200th batch</th>\n",
              "      <td>5.775470</td>\n",
              "      <td>6.109134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 18400th batch</th>\n",
              "      <td>6.192812</td>\n",
              "      <td>5.797848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 18600th batch</th>\n",
              "      <td>5.719205</td>\n",
              "      <td>5.747447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 18800th batch</th>\n",
              "      <td>6.023054</td>\n",
              "      <td>5.976269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 19000th batch</th>\n",
              "      <td>6.267450</td>\n",
              "      <td>5.911942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss in 19200th batch</th>\n",
              "      <td>5.886949</td>\n",
              "      <td>6.106186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f2fb9d7-a5f6-4418-9f46-497b2fd10861')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f2fb9d7-a5f6-4418-9f46-497b2fd10861 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f2fb9d7-a5f6-4418-9f46-497b2fd10861');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-755ba4a8-9b48-47ac-a52f-9968a06b9f86\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-755ba4a8-9b48-47ac-a52f-9968a06b9f86')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-755ba4a8-9b48-47ac-a52f-9968a06b9f86 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZYB1SfhTw4F"
      },
      "source": [
        "## Observations from Results\n",
        "Results show a clear comparison between the two models. The key metrics used are cumulative rewards, hit rate (hr), and normalized discounted cumulative gain (ndcg) at different top-k recommendations (5, 10, 15, 20). The inclusion of item features seems to have improved performance in terms of cumulative rewards and other metrics, as evident from the comparison of the outputs from SNQN_new.py (without item features) and SNQN_parent_new.py (with item features). In both models, the metrics improve as the number of top-k recommendations increases, a common trend in recommender systems. The loss decreases over batches in both models, indicating that the models are learning and optimizing over time. The model with item features generally performs better, suggesting that including item features is beneficial for improving recommendation quality, especially for cold items/users.\n",
        "\n",
        "## Conclusion\n",
        "The approach and results are well-aligned with the specified requirements. It have successfully trained and compared session-based DRL recommenders with and without item features, demonstrating the effectiveness of including such features in improving recommendation performance for e-commerce applications."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}